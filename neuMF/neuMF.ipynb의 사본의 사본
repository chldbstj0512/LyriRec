{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyPh4gpPdYDVPZP7Ai7TSHp0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eUuriR2HcKm3","executionInfo":{"status":"ok","timestamp":1701845839719,"user_tz":-540,"elapsed":23294,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"97bc60c2-6916-449e-be5e-6b7777b3a2a6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import json\n","import pickle"],"metadata":{"id":"v3glkGrGcML4","executionInfo":{"status":"ok","timestamp":1701845840849,"user_tz":-540,"elapsed":1132,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/집교 2_Team P/user-track-listen_count.csv')"],"metadata":{"id":"kRDZDyXPcOp9","executionInfo":{"status":"ok","timestamp":1701845842552,"user_tz":-540,"elapsed":1706,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df_embedding = pd.read_pickle('/content/drive/MyDrive/집교 2_Team P/lyrics_Embedding/all_embeddings_combined.pkl')"],"metadata":{"id":"smE1s0RFcO7Y","executionInfo":{"status":"ok","timestamp":1701845844003,"user_tz":-540,"elapsed":1454,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Pickle 파일 읽기\n","with open('/content/drive/MyDrive/집교 2_Team P/lyrics_Embedding/all_embeddings_combined.pkl', 'rb') as file:\n","    data = pickle.load(file)\n","\n","# DataFrame으로 변환\n","df_embedding = pd.DataFrame(data, columns=['embedding', 'track_id'])\n","\n","# track_id를 정수로 변환 (필요하다면)\n","df_embedding['track_id'] = df_embedding['track_id'].astype(int)\n","\n","# 'embedding' 열을 768차원의 각 차원으로 나누기\n","# df_embedding[['embedding_{}'.format(i) for i in range(768)]] = pd.DataFrame(df_embedding['embedding'].tolist(), index=df_embedding.index)\n","\n","# 'embedding' 열 삭제\n","# df_embedding = df_embedding.drop(['embedding'], axis=1)\n","\n","# DataFrame 확인\n","print(df_embedding.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81ljehBxekam","executionInfo":{"status":"ok","timestamp":1701845844003,"user_tz":-540,"elapsed":4,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"1983598a-0a55-44e0-9ad6-47e78f561a0f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["                                           embedding  track_id\n","0  [0.012072664, 0.17292306, 0.0061238254, 0.0707...         2\n","1  [-0.17554894, 0.24209566, 0.4195969, -0.185033...         8\n","2  [-0.096951924, 0.0034472912, 0.005701333, 0.01...      1524\n","3  [-0.21775067, 0.244962, 0.24090661, 0.1647732,...      1785\n","4  [-0.069424234, -0.016805744, 0.21406727, -0.27...      1787\n"]}]},{"cell_type":"code","source":["df = pd.merge(df, df_embedding, on=['track_id'], how='left')"],"metadata":{"id":"DfpRw-VmeiN_","executionInfo":{"status":"ok","timestamp":1701845845065,"user_tz":-540,"elapsed":1065,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4G-Q5aiNcHSA","executionInfo":{"status":"ok","timestamp":1701849303658,"user_tz":-540,"elapsed":2621,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"b295e8fc-80f9-44c0-f103-8c62432a6d3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["num_users: 24458\n","num_items: 31110\n","Using device: cuda\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm import tqdm\n","import numpy as np\n","from sklearn.metrics import mean_squared_error\n","# 가상의 데이터 프레임 생성 (예시)\n","# ...\n","\n","# Label Encoding\n","user_encoder = LabelEncoder()\n","item_encoder = LabelEncoder()\n","\n","df['user_id'] = user_encoder.fit_transform(df['user_id'])\n","df['track_id'] = item_encoder.fit_transform(df['track_id'])\n","df.loc[df['listen_count_bin'] == '10~2704', 'listen_count_bin'] = 10\n","df['listen_count_bin'] = df['listen_count_bin'].astype(int)\n","\n","# PyTorch DataLoader에 맞게 데이터 변환\n","def df_to_tensor(dataset):\n","    users = torch.tensor(dataset['user_id'].values, dtype=torch.long)\n","    items = torch.tensor(dataset['track_id'].values, dtype=torch.long)\n","    ratings = torch.tensor(dataset['listen_count_bin'].values, dtype=torch.float)\n","    return users, items, ratings\n","\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","train_users, train_items, train_ratings = df_to_tensor(train_df)\n","test_users, test_items, test_ratings = df_to_tensor(test_df)\n","\n","train_data = TensorDataset(train_users, train_items, train_ratings)\n","test_data = TensorDataset(test_users, test_items, test_ratings)\n","\n","train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=256, shuffle=False)\n","\n","class NeuMF(nn.Module):\n","    def __init__(self, num_users, num_items, embedding_size, mlp_hidden_size):\n","        super(NeuMF, self).__init__()\n","        # Matrix Factorization\n","        self.user_embedding_mf = nn.Embedding(num_users, embedding_size)\n","        self.item_embedding_mf = nn.Embedding(num_items, embedding_size)\n","        # Multi-Layer Perceptron\n","        self.user_embedding_mlp = nn.Embedding(num_users, mlp_hidden_size)\n","        self.item_embedding_mlp = nn.Embedding(num_items, mlp_hidden_size)\n","        self.mlp_layers = nn.Sequential(\n","            nn.Linear(2 * mlp_hidden_size, mlp_hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(mlp_hidden_size, int(mlp_hidden_size/2)),\n","            nn.ReLU(),\n","            nn.Linear(int(mlp_hidden_size/2), int(mlp_hidden_size/4)),\n","            nn.ReLU(),\n","            nn.Linear(int(mlp_hidden_size/4), int(mlp_hidden_size/8)),\n","\n","        )\n","        # Final Layer\n","        self.final_layer = nn.Linear(int(mlp_hidden_size/8+embedding_size), 1)\n","\n","    def forward(self, user, item):\n","        # Matrix Factorization\n","        user_embedding_mf = self.user_embedding_mf(user)\n","        item_embedding_mf = self.item_embedding_mf(item)\n","        mf_output = torch.mul(user_embedding_mf, item_embedding_mf)\n","\n","        # Multi-Layer Perceptron\n","        user_embedding_mlp = self.user_embedding_mlp(user)\n","        item_embedding_mlp = self.item_embedding_mlp(item)\n","        mlp_input = torch.cat((user_embedding_mlp, item_embedding_mlp), dim=1)\n","        mlp_output = self.mlp_layers(mlp_input)\n","        # Concatenate MF and MLP outputs\n","        final_input = torch.cat((mf_output, mlp_output), dim=1)\n","\n","        # Final prediction\n","        prediction = self.final_layer(final_input)\n","        return prediction.view(-1)\n","\n","\n","# NeuMF 모델 초기화\n","num_users = len(user_encoder.classes_)\n","num_items = len(item_encoder.classes_)\n","print(\"num_users:\",num_users)\n","print(\"num_items:\",num_items)\n","\n","\n","# 학습 및 평가 코드는 이전과 유사\n","# ...\n","# CUDA 디바이스 설정\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","def train_(emb,mlp,n_epoch):\n","  embedding_size = emb\n","  mlp_hidden_size = mlp\n","\n","  neumf_model = NeuMF(num_users, num_items, embedding_size, mlp_hidden_size)\n","\n","  # 손실 함수 및 최적화 함수 정의\n","  criterion = nn.MSELoss()\n","  optimizer = optim.Adam(neumf_model.parameters(), lr=0.001)\n","  # NCF 모델 정의 및 GPU로 이동\n","  # model = NCF(num_users=len(user_encoder.classes_), num_items=len(item_encoder.classes_), embedding_size=embedding_size)\n","  neumf_model.to(device)\n","  criterion = nn.MSELoss()\n","  optimizer = optim.Adam(neumf_model.parameters(), lr=0.001)\n","  # tqdm을 사용하여 학습 및 테스트 진행 상황 확인\n","  num_epochs = n_epoch\n","  for epoch in range(num_epochs):\n","      neumf_model.train()\n","      total_loss = 0\n","      for user, item, rating in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n","          optimizer.zero_grad()\n","          user, item, rating = user.to(device), item.to(device), rating.to(device)  # GPU로 이동\n","          output = neumf_model(user, item)\n","          loss = criterion(output, rating.unsqueeze(1))\n","          loss.backward()\n","          optimizer.step()\n","          total_loss += loss.item()\n","\n","      avg_loss = total_loss / len(train_loader)\n","      print(f'Epoch {epoch+1}/{num_epochs}, Avg. Loss: {avg_loss:.4f}')\n","\n","      # 각 에폭이 끝날 때마다 테스트 데이터에 대한 예측 수행\n","      neumf_model.eval()\n","      all_predictions = []\n","      with torch.no_grad():\n","          for user, item, _ in tqdm(test_loader, desc=f'Testing Epoch {epoch+1}'):\n","              user, item = user.to(device), item.to(device)  # GPU로 이동\n","              output = neumf_model(user, item)\n","              all_predictions.append(output)\n","\n","      # RMSE 계산\n","      predictions = torch.cat(all_predictions).squeeze().cpu().numpy()  # CPU로 이동 후 numpy로 변환\n","      rmse = np.sqrt(mean_squared_error(test_df['listen_count_bin'].values, predictions))\n","      print(f'Epoch {epoch+1}/{num_epochs}, RMSE on test set: {rmse}')"]},{"cell_type":"code","source":["train_(128,512,10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"KUgHfnO3poiF","executionInfo":{"status":"error","timestamp":1701850321514,"user_tz":-540,"elapsed":1017858,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"64a76e8c-9e3b-4ab5-f211-eb41490b54a9"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/10:   0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 1/10: 100%|█████████▉| 14539/14544 [02:03<00:00, 120.07it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 1/10: 100%|██████████| 14544/14544 [02:03<00:00, 117.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Avg. Loss: 7.1115\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 1: 100%|██████████| 3636/3636 [00:12<00:00, 287.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, RMSE on test set: 2.663549288334055\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10:   0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 2/10: 100%|█████████▉| 14537/14544 [02:05<00:00, 119.68it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 2/10: 100%|██████████| 14544/14544 [02:05<00:00, 115.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Avg. Loss: 7.0886\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 2: 100%|██████████| 3636/3636 [00:12<00:00, 288.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, RMSE on test set: 2.6626611772772577\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10:   0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 3/10: 100%|█████████▉| 14531/14544 [02:04<00:00, 118.51it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 3/10: 100%|██████████| 14544/14544 [02:05<00:00, 116.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Avg. Loss: 7.0885\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 3: 100%|██████████| 3636/3636 [00:12<00:00, 284.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, RMSE on test set: 2.6626622640793016\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10:   0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 4/10: 100%|█████████▉| 14538/14544 [02:05<00:00, 118.25it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 4/10: 100%|██████████| 14544/14544 [02:06<00:00, 115.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Avg. Loss: 7.0884\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 4: 100%|██████████| 3636/3636 [00:12<00:00, 290.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, RMSE on test set: 2.663057775999707\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10:   0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 5/10: 100%|█████████▉| 14535/14544 [02:05<00:00, 115.20it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 5/10: 100%|██████████| 14544/14544 [02:05<00:00, 115.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Avg. Loss: 7.0881\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 5: 100%|██████████| 3636/3636 [00:12<00:00, 284.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, RMSE on test set: 2.6628357437052914\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10:   0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 6/10: 100%|█████████▉| 14538/14544 [02:06<00:00, 118.15it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 6/10: 100%|██████████| 14544/14544 [02:06<00:00, 115.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Avg. Loss: 7.0881\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 6: 100%|██████████| 3636/3636 [00:12<00:00, 285.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, RMSE on test set: 2.6627185830655047\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10:   0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 7/10: 100%|█████████▉| 14534/14544 [02:07<00:00, 113.77it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 7/10: 100%|██████████| 14544/14544 [02:07<00:00, 114.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Avg. Loss: 7.0880\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 7: 100%|██████████| 3636/3636 [00:12<00:00, 284.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, RMSE on test set: 2.663166549544488\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10:   0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 8/10:  39%|███▊      | 5612/14544 [00:48<01:17, 115.11it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-8dfcfc548f34>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-3fda9c99368d>\u001b[0m in \u001b[0;36mtrain_\u001b[0;34m(emb, mlp, n_epoch)\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0mneumf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Epoch {epoch+1}/{num_epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m           \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# GPU로 이동\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}