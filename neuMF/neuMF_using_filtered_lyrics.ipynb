{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyMs4KZZQWHO0pkfJp+f07SZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eUuriR2HcKm3","executionInfo":{"status":"ok","timestamp":1701948468351,"user_tz":-540,"elapsed":33485,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"7b83f473-8d6b-4fb0-dddf-cf180f31ca7e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import json\n","import pickle"],"metadata":{"id":"v3glkGrGcML4","executionInfo":{"status":"ok","timestamp":1701948469989,"user_tz":-540,"elapsed":1643,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/집교 2_Team P/user-track-listen_count_filtered5.csv')"],"metadata":{"id":"kRDZDyXPcOp9","executionInfo":{"status":"ok","timestamp":1701948473306,"user_tz":-540,"elapsed":3342,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Pickle 파일 읽기\n","with open('/content/drive/MyDrive/집교 2_Team P/lyrics_Embedding/all_embeddings_full.pkl', 'rb') as file:\n","    data = pickle.load(file)\n","\n","# DataFrame으로 변환\n","df_embedding = pd.DataFrame(data, columns=['embedding', 'track_id'])\n","\n","# track_id를 정수로 변환 (필요하다면)\n","df_embedding['track_id'] = df_embedding['track_id'].astype(int)\n","\n","# 'embedding' 열을 768차원의 각 차원으로 나누기\n","# df_embedding[['embedding_{}'.format(i) for i in range(768)]] = pd.DataFrame(df_embedding['embedding'].tolist(), index=df_embedding.index)\n","\n","# 'embedding' 열 삭제\n","# df_embedding = df_embedding.drop(['embedding'], axis=1)\n","\n","# DataFrame 확인\n","print(df_embedding.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81ljehBxekam","executionInfo":{"status":"ok","timestamp":1701948475327,"user_tz":-540,"elapsed":2041,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"a9b1a32f-b685-4fc5-905a-c2c38a7c983c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["                                           embedding  track_id\n","0  [0.012072664, 0.17292306, 0.0061238254, 0.0707...         2\n","1  [-0.17554894, 0.24209566, 0.4195969, -0.185033...         8\n","2  [-0.096951924, 0.0034472912, 0.005701333, 0.01...      1524\n","3  [-0.21775067, 0.244962, 0.24090661, 0.1647732,...      1785\n","4  [-0.069424234, -0.016805744, 0.21406727, -0.27...      1787\n"]}]},{"cell_type":"code","source":["print(df.shape)\n","df = pd.merge(df, df_embedding, on='track_id', how='inner')\n","df.shape"],"metadata":{"id":"DfpRw-VmeiN_","executionInfo":{"status":"ok","timestamp":1701948476472,"user_tz":-540,"elapsed":1152,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"53f16620-234e-4e27-d1c5-6cb8c12f9cd3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(4645010, 4)\n"]},{"output_type":"execute_result","data":{"text/plain":["(4644051, 5)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","user_encoder = LabelEncoder()\n","track_encoder = LabelEncoder()\n","lyrics_encoder = LabelEncoder()\n","df['user_id'] = user_encoder.fit_transform(df['user_id'])\n","df['track_id'] = track_encoder.fit_transform(df['track_id'])\n","df_embedding['track_id'] = lyrics_encoder.fit_transform(df_embedding['track_id'])"],"metadata":{"id":"CxSJcOgPCIkC","executionInfo":{"status":"ok","timestamp":1701948476981,"user_tz":-540,"elapsed":523,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["lyrics_dict = dict(zip(df_embedding['track_id'], df_embedding['embedding']))"],"metadata":{"id":"g7zb4HleCKEF","executionInfo":{"status":"ok","timestamp":1701948476982,"user_tz":-540,"elapsed":13,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# !pip install torch torchvision -U\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","# 데이터 불러오기 (예시: CSV 파일)\n","# Label Encoding\n","df.loc[df['listen_count_bin'] == '10~2704', 'listen_count_bin'] = 10\n","df['listen_count_bin'] = df['listen_count_bin'].astype(int)\n","# PyTorch DataLoader에 맞게 데이터 변환\n","def df_to_tensor(dataset):\n","    users = torch.tensor(dataset['user_id'].values, dtype=torch.int)\n","    items = torch.tensor(dataset['track_id'].values, dtype=torch.int)\n","    ratings = torch.tensor(dataset['listen_count_bin'].values, dtype=torch.float)\n","    lyrics_embeddings = torch.tensor(np.vstack(dataset['embedding'].values), dtype=torch.float)\n","    return users, items, ratings, lyrics_embeddings\n","\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","train_users, train_items, train_ratings, train_lyrics_embeddings = df_to_tensor(train_df)\n","test_users, test_items, test_ratings,test_lyrics_embeddings = df_to_tensor(test_df)\n","\n","train_data = TensorDataset(train_users, train_items, train_ratings,train_lyrics_embeddings)\n","test_data = TensorDataset(test_users, test_items, test_ratings,test_lyrics_embeddings)\n","\n","train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=256, shuffle=False)\n","num_users = (df['user_id'].nunique())\n","num_items = (df['track_id'].nunique())\n","print(num_users)\n","print(num_items)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApBWgA3mCSOI","executionInfo":{"status":"ok","timestamp":1701948519431,"user_tz":-540,"elapsed":16228,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"d94ab25d-5616-41ba-b51f-6eddfe4e24fa"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["23761\n","28309\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4G-Q5aiNcHSA","executionInfo":{"status":"ok","timestamp":1701948634160,"user_tz":-540,"elapsed":581,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"91d0394a-a377-4a7e-f990-bd8373d12fea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["class NeuMF(nn.Module):\n","    def __init__(self, num_users, num_items, embedding_size, mlp_hidden_size):\n","        super(NeuMF, self).__init__()\n","        # Matrix Factorization\n","        self.user_embedding_mf = nn.Embedding(num_users, embedding_size)\n","        self.item_embedding_mf = nn.Embedding(num_items, embedding_size)\n","        # Multi-Layer Perceptron\n","        self.user_embedding_mlp = nn.Embedding(num_users, mlp_hidden_size)\n","        self.item_embedding_mlp = nn.Embedding(num_items, mlp_hidden_size)\n","        self.lyrics_embedding = nn.Linear(768, embedding_size)\n","        self.mlp_layers = nn.Sequential(\n","            nn.Linear(3 * mlp_hidden_size, mlp_hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(mlp_hidden_size, int(mlp_hidden_size/2)),\n","            nn.ReLU(),\n","            nn.Linear(int(mlp_hidden_size/2), int(mlp_hidden_size/4)),\n","            nn.ReLU(),\n","            nn.Linear(int(mlp_hidden_size/4), int(mlp_hidden_size/8)),\n","\n","        )\n","        # Final Layer\n","        self.final_layer = nn.Linear(int(mlp_hidden_size/8+embedding_size), 1)\n","\n","    def forward(self, user, item,lyrics_embedding):\n","        # Matrix Factorization\n","        user_embedding_mf = self.user_embedding_mf(user)\n","        item_embedding_mf = self.item_embedding_mf(item)\n","        mf_output = torch.mul(user_embedding_mf, item_embedding_mf)\n","\n","        # Multi-Layer Perceptron\n","        user_embedding_mlp = self.user_embedding_mlp(user)\n","        item_embedding_mlp = self.item_embedding_mlp(item)\n","        lyrics_embedding = self.lyrics_embedding(lyrics_embedding.reshape(lyrics_embedding.shape[0],768))\n","        mlp_input = torch.cat((user_embedding_mlp, item_embedding_mlp,lyrics_embedding), dim=1)\n","        mlp_output = self.mlp_layers(mlp_input)\n","        # Concatenate MF and MLP outputs\n","        final_input = torch.cat((mf_output, mlp_output), dim=1)\n","\n","        # Final prediction\n","        prediction = self.final_layer(final_input)\n","        return prediction.view(-1)\n","\n","# 학습 및 평가 코드는 이전과 유사\n","# ...\n","# CUDA 디바이스 설정\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","def train_(emb,mlp,n_epoch):\n","  embedding_size = emb\n","  mlp_hidden_size = mlp\n","\n","  neumf_model = NeuMF(num_users, num_items, embedding_size, mlp_hidden_size)\n","\n","  # 손실 함수 및 최적화 함수 정의\n","  criterion = nn.MSELoss()\n","  optimizer = optim.Adam(neumf_model.parameters(), lr=0.001)\n","  # NCF 모델 정의 및 GPU로 이동\n","  # model = NCF(num_users=len(user_encoder.classes_), num_items=len(item_encoder.classes_), embedding_size=embedding_size)\n","  neumf_model.to(device)\n","  criterion = nn.MSELoss()\n","  optimizer = optim.Adam(neumf_model.parameters(), lr=0.001)\n","  # tqdm을 사용하여 학습 및 테스트 진행 상황 확인\n","  num_epochs = n_epoch\n","  for epoch in range(num_epochs):\n","      neumf_model.train()\n","      total_loss = 0\n","      for user, item, rating,lyrics_embedding in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n","          optimizer.zero_grad()\n","          user, item, rating,lyrics_embedding = user.to(device), item.to(device), rating.to(device),lyrics_embedding.to(device)  # GPU로 이동\n","          output = neumf_model(user, item,lyrics_embedding)\n","          loss = criterion(output, rating.unsqueeze(1))\n","          loss.backward()\n","          optimizer.step()\n","          total_loss += loss.item()\n","\n","      avg_loss = total_loss / len(train_loader)\n","      print(f'Epoch {epoch+1}/{num_epochs}, Avg. Loss: {avg_loss:.4f}')\n","\n","      # 각 에폭이 끝날 때마다 테스트 데이터에 대한 예측 수행\n","      neumf_model.eval()\n","      all_predictions = []\n","      with torch.no_grad():\n","          for user, item, _,lyrics_embedding in tqdm(test_loader, desc=f'Testing Epoch {epoch+1}'):\n","              user, item,lyrics_embedding = user.to(device), item.to(device),lyrics_embedding.to(device)  # GPU로 이동\n","              output = neumf_model(user, item,lyrics_embedding)\n","              all_predictions.append(output)\n","\n","      # RMSE 계산\n","      predictions = torch.cat(all_predictions).squeeze().cpu().numpy()  # CPU로 이동 후 numpy로 변환\n","      rmse = np.sqrt(mean_squared_error(test_df['listen_count_bin'].values, predictions))\n","      print(f'Epoch {epoch+1}/{num_epochs}, RMSE on test set: {rmse}')"]},{"cell_type":"code","source":["train_(64,64,10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUgHfnO3poiF","executionInfo":{"status":"ok","timestamp":1701949816009,"user_tz":-540,"elapsed":1176196,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"3dd115f1-96e4-48b9-b209-4f4c339052c2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 1/10: 100%|█████████▉| 14502/14513 [01:39<00:00, 150.89it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 1/10: 100%|██████████| 14513/14513 [01:39<00:00, 145.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Avg. Loss: 1.6541\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 1: 100%|██████████| 3629/3629 [00:15<00:00, 229.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, RMSE on test set: 1.280509463407143\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 2/10: 100%|█████████▉| 14510/14513 [01:40<00:00, 151.34it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 2/10: 100%|██████████| 14513/14513 [01:40<00:00, 144.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Avg. Loss: 1.6459\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 2: 100%|██████████| 3629/3629 [00:15<00:00, 231.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, RMSE on test set: 1.2808157682407189\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 3/10: 100%|█████████▉| 14512/14513 [01:40<00:00, 155.00it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 3/10: 100%|██████████| 14513/14513 [01:40<00:00, 144.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Avg. Loss: 1.6437\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 3: 100%|██████████| 3629/3629 [00:15<00:00, 236.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, RMSE on test set: 1.2803792505809994\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 4/10: 100%|█████████▉| 14502/14513 [01:41<00:00, 146.43it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 4/10: 100%|██████████| 14513/14513 [01:41<00:00, 143.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Avg. Loss: 1.6430\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 4: 100%|██████████| 3629/3629 [00:15<00:00, 234.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, RMSE on test set: 1.2803727214617995\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 5/10: 100%|█████████▉| 14499/14513 [01:40<00:00, 152.13it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 5/10: 100%|██████████| 14513/14513 [01:40<00:00, 144.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Avg. Loss: 1.6429\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 5: 100%|██████████| 3629/3629 [00:15<00:00, 235.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, RMSE on test set: 1.2804588615049213\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 6/10: 100%|█████████▉| 14501/14513 [01:42<00:00, 148.27it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 6/10: 100%|██████████| 14513/14513 [01:42<00:00, 141.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Avg. Loss: 1.6430\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 6: 100%|██████████| 3629/3629 [00:15<00:00, 228.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, RMSE on test set: 1.2804467843130043\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 7/10: 100%|█████████▉| 14498/14513 [01:41<00:00, 150.82it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 7/10: 100%|██████████| 14513/14513 [01:42<00:00, 141.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Avg. Loss: 1.6429\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 7: 100%|██████████| 3629/3629 [00:16<00:00, 224.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, RMSE on test set: 1.2803689573820536\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 8/10: 100%|█████████▉| 14509/14513 [01:40<00:00, 154.46it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 8/10: 100%|██████████| 14513/14513 [01:41<00:00, 143.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Avg. Loss: 1.6429\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 8: 100%|██████████| 3629/3629 [00:15<00:00, 227.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, RMSE on test set: 1.280348984062504\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 9/10: 100%|█████████▉| 14512/14513 [01:40<00:00, 151.73it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 9/10: 100%|██████████| 14513/14513 [01:40<00:00, 144.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Avg. Loss: 1.6429\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 9: 100%|██████████| 3629/3629 [00:16<00:00, 225.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, RMSE on test set: 1.2804121432886597\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 10/10: 100%|█████████▉| 14497/14513 [01:40<00:00, 149.50it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 10/10: 100%|██████████| 14513/14513 [01:40<00:00, 143.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Avg. Loss: 1.6429\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 10: 100%|██████████| 3629/3629 [00:15<00:00, 230.43it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, RMSE on test set: 1.2803697066472184\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["train_(128,128,10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lJhx5ioFC2Vg","executionInfo":{"status":"error","timestamp":1701950683304,"user_tz":-540,"elapsed":867330,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"f8cff84a-f590-4af5-cc01-4a7b91e678f6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 1/10: 100%|█████████▉| 14507/14513 [01:46<00:00, 140.87it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 1/10: 100%|██████████| 14513/14513 [01:46<00:00, 136.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Avg. Loss: 1.6521\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 1: 100%|██████████| 3629/3629 [00:15<00:00, 231.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, RMSE on test set: 1.28039627000155\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 2/10: 100%|█████████▉| 14507/14513 [01:49<00:00, 139.59it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 2/10: 100%|██████████| 14513/14513 [01:49<00:00, 132.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Avg. Loss: 1.6439\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 2: 100%|██████████| 3629/3629 [00:15<00:00, 229.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, RMSE on test set: 1.2804043953236999\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 3/10: 100%|█████████▉| 14498/14513 [01:49<00:00, 139.51it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 3/10: 100%|██████████| 14513/14513 [01:49<00:00, 132.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Avg. Loss: 1.6432\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 3: 100%|██████████| 3629/3629 [00:16<00:00, 222.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, RMSE on test set: 1.2804900084152726\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 4/10: 100%|█████████▉| 14508/14513 [01:49<00:00, 135.35it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 4/10: 100%|██████████| 14513/14513 [01:49<00:00, 132.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Avg. Loss: 1.6432\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 4: 100%|██████████| 3629/3629 [00:16<00:00, 226.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, RMSE on test set: 1.2804177635930978\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 5/10: 100%|█████████▉| 14502/14513 [01:49<00:00, 138.78it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 5/10: 100%|██████████| 14513/14513 [01:50<00:00, 131.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Avg. Loss: 1.6432\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 5: 100%|██████████| 3629/3629 [00:15<00:00, 232.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, RMSE on test set: 1.2806646852732335\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 6/10: 100%|█████████▉| 14500/14513 [01:50<00:00, 110.27it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 6/10: 100%|██████████| 14513/14513 [01:50<00:00, 131.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Avg. Loss: 1.6431\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 6: 100%|██████████| 3629/3629 [00:15<00:00, 234.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, RMSE on test set: 1.2804060386160356\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10:   0%|          | 0/14513 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 7/10: 100%|█████████▉| 14502/14513 [01:49<00:00, 130.75it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([168, 1])) that is different to the input size (torch.Size([168])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 7/10: 100%|██████████| 14513/14513 [01:50<00:00, 131.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Avg. Loss: 1.6431\n"]},{"output_type":"stream","name":"stderr","text":["Testing Epoch 7:  40%|███▉      | 1439/3629 [00:06<00:09, 225.60it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-58db4dadc2fd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-4f83c9c57562>\u001b[0m in \u001b[0;36mtrain_\u001b[0;34m(emb, mlp, n_epoch)\u001b[0m\n\u001b[1;32m     83\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlyrics_embedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Testing Epoch {epoch+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m               \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlyrics_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlyrics_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# GPU로 이동\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m               \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneumf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlyrics_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m               \u001b[0mall_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-4f83c9c57562>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, user, item, lyrics_embedding)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlyrics_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlyrics_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrics_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrics_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mmlp_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_embedding_mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_embedding_mlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlyrics_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mmlp_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Concatenate MF and MLP outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mfinal_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["train_(256,256,10)"],"metadata":{"id":"L2Vv5rlzC5Ir","executionInfo":{"status":"aborted","timestamp":1701950683305,"user_tz":-540,"elapsed":10,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":null,"outputs":[]}]}