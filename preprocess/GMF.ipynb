{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPNCud4CJEIPZ0xrYu73FwP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Uo8EqeDKXvo","executionInfo":{"status":"ok","timestamp":1701850241970,"user_tz":-540,"elapsed":31210,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"e0680192-5111-4861-8791-37301806768b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import json\n","import pickle"],"metadata":{"id":"IWKr4WchKbkn","executionInfo":{"status":"ok","timestamp":1701850242731,"user_tz":-540,"elapsed":765,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/집교 2_Team P/user-track-listen_count.csv')"],"metadata":{"id":"4MOSJkXjKcb2","executionInfo":{"status":"ok","timestamp":1701850246368,"user_tz":-540,"elapsed":3639,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm import tqdm\n","import numpy as np\n","from sklearn.metrics import mean_squared_error\n","# 가상의 데이터 프레임 생성 (예시)\n","# ...\n","\n","# Label Encoding\n","user_encoder = LabelEncoder()\n","item_encoder = LabelEncoder()\n","\n","df['user_id'] = user_encoder.fit_transform(df['user_id'])\n","df['track_id'] = item_encoder.fit_transform(df['track_id'])\n","df.loc[df['listen_count_bin'] == '10~2704', 'listen_count_bin'] = 10\n","df['listen_count_bin'] = df['listen_count_bin'].astype(int)\n","\n","# PyTorch DataLoader에 맞게 데이터 변환\n","def df_to_tensor(dataset):\n","    users = torch.tensor(dataset['user_id'].values, dtype=torch.long)\n","    items = torch.tensor(dataset['track_id'].values, dtype=torch.long)\n","    ratings = torch.tensor(dataset['listen_count_bin'].values, dtype=torch.float)\n","    return users, items, ratings\n","\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","train_users, train_items, train_ratings = df_to_tensor(train_df)\n","test_users, test_items, test_ratings = df_to_tensor(test_df)\n","\n","train_data = TensorDataset(train_users, train_items, train_ratings)\n","test_data = TensorDataset(test_users, test_items, test_ratings)\n","\n","train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=256, shuffle=False)"],"metadata":{"id":"LwNw678yKcr4","executionInfo":{"status":"ok","timestamp":1701850253562,"user_tz":-540,"elapsed":7197,"user":{"displayName":"나주영","userId":"11176719384042417975"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class GMF(nn.Module):\n","    def __init__(self, num_users, num_items, embedding_size):\n","        super(GMF, self).__init__()\n","        self.user_embedding = nn.Embedding(num_users, embedding_size)\n","        self.item_embedding = nn.Embedding(num_items, embedding_size)\n","        self.output_layer = nn.Linear(embedding_size, 1)\n","\n","    def forward(self, user, item):\n","        user_embedding = self.user_embedding(user)\n","        item_embedding = self.item_embedding(item)\n","        elementwise_product = torch.mul(user_embedding, item_embedding)\n","        prediction = self.output_layer(elementwise_product)\n","        return prediction.view(-1)\n","\n","# 데이터 전처리 및 DataLoader 생성\n","# ...\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","# 모델 초기화\n","num_users = len(user_encoder.classes_)\n","num_items = len(item_encoder.classes_)\n","def train_gmf(embedding_size):\n","\n","  gmf_model = GMF(num_users, num_items, embedding_size).to(device)\n","\n","  # 손실 함수 및 최적화 함수 정의\n","  criterion = nn.MSELoss()\n","  optimizer = optim.Adam(gmf_model.parameters(), lr=0.001)\n","\n","  # 학습 및 평가\n","  num_epochs = 10\n","  for epoch in range(num_epochs):\n","      gmf_model.train()\n","      for batch in tqdm(train_loader):\n","          users, items, ratings = batch\n","          users = users.to(device)\n","          items = items.to(device)\n","          ratings = ratings.to(device)\n","          optimizer.zero_grad()\n","          predictions = gmf_model(users, items)\n","          loss = criterion(predictions, ratings.unsqueeze(1))\n","          loss.backward()\n","          optimizer.step()\n","\n","      gmf_model.eval()\n","      all_predictions = []\n","      with torch.no_grad():\n","\n","          for batch in tqdm(test_loader):\n","              users, items, ratings = batch\n","              users = users.to(device)\n","              items = items.to(device)\n","              predictions = gmf_model(users, items)\n","              all_predictions.append(predictions)\n","\n","      predictions = torch.cat(all_predictions).squeeze().cpu().numpy()\n","\n","      rmse = np.sqrt(mean_squared_error(test_df['listen_count_bin'].values, predictions))\n","      print(f'Epoch {epoch+1}/{num_epochs}, RMSE on test set: {rmse}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOdJxk8yKnO5","executionInfo":{"status":"ok","timestamp":1701851970326,"user_tz":-540,"elapsed":2,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"d50aa6f7-c946-4c58-e51f-2fc5e4ea2939"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["train_gmf(32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mI7IjuUkLBL0","executionInfo":{"status":"ok","timestamp":1701852696504,"user_tz":-540,"elapsed":723272,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"96220aed-f44b-409d-bdfe-dfd95f0b0833"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 14531/14544 [00:59<00:00, 248.51it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [00:59<00:00, 243.29it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 333.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, RMSE on test set: 2.6626089501879733\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14526/14544 [01:01<00:00, 211.29it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 235.69it/s]\n","100%|██████████| 3636/3636 [00:11<00:00, 330.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, RMSE on test set: 2.6625966443370723\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14537/14544 [01:01<00:00, 241.14it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 235.77it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 333.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, RMSE on test set: 2.662587552912467\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14522/14544 [01:01<00:00, 245.02it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 236.02it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 332.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, RMSE on test set: 2.6626262742589457\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14521/14544 [01:01<00:00, 233.59it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 236.77it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 331.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, RMSE on test set: 2.662570871074185\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14542/14544 [01:01<00:00, 236.74it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 235.88it/s]\n","100%|██████████| 3636/3636 [00:11<00:00, 330.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, RMSE on test set: 2.6626276012879417\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14533/14544 [01:01<00:00, 243.86it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 236.74it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 333.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, RMSE on test set: 2.6625761122910983\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14539/14544 [01:01<00:00, 243.91it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 235.49it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 333.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, RMSE on test set: 2.6625956537413327\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14529/14544 [01:01<00:00, 237.58it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 236.33it/s]\n","100%|██████████| 3636/3636 [00:11<00:00, 328.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, RMSE on test set: 2.6626270989738576\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14520/14544 [01:01<00:00, 245.05it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 237.04it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 333.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, RMSE on test set: 2.662577747559464\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["train_gmf(128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Ro6sK7iHLK6z","executionInfo":{"status":"error","timestamp":1701853151652,"user_tz":-540,"elapsed":441212,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"697d19cf-8579-4172-a4e6-ff127e61687c"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14540/14544 [01:00<00:00, 252.29it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:00<00:00, 241.01it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 332.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, RMSE on test set: 2.662685618898964\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14522/14544 [01:01<00:00, 236.05it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 235.82it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 334.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, RMSE on test set: 2.6626952871431815\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14530/14544 [01:01<00:00, 242.06it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 236.41it/s]\n","100%|██████████| 3636/3636 [00:11<00:00, 329.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, RMSE on test set: 2.6628105995860967\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14543/14544 [01:01<00:00, 239.60it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 235.74it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 334.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, RMSE on test set: 2.6626974433108175\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14523/14544 [01:01<00:00, 237.36it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 235.32it/s]\n","100%|██████████| 3636/3636 [00:10<00:00, 330.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, RMSE on test set: 2.6626610083521167\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|█████████▉| 14520/14544 [01:01<00:00, 243.26it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","100%|██████████| 14544/14544 [01:01<00:00, 236.02it/s]\n","100%|██████████| 3636/3636 [00:11<00:00, 329.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, RMSE on test set: 2.662656017361288\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/14544 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","  9%|▉         | 1317/14544 [00:05<00:56, 235.75it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-f89aa5541000>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_gmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-c1b1868de9f2>\u001b[0m in \u001b[0;36mtrain_gmf\u001b[0;34m(embedding_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mgmf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m           \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m           \u001b[0musers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["!pip install pyro-ppl\n","import torch\n","import pyro\n","import pyro.distributions as dist\n","from pyro.infer import SVI, Trace_ELBO\n","from pyro.optim import Adam\n","\n","# 가상의 데이터셋 생성 (예시: MovieLens 데이터셋)\n","# ...\n","\n","# PyTorch DataLoader에 맞게 데이터 변환\n","def df_to_tensor(dataset):\n","    users = torch.tensor(dataset['user_id'].values, dtype=torch.long)\n","    items = torch.tensor(dataset['item_id'].values, dtype=torch.long)\n","    ratings = torch.tensor(dataset['rating'].values, dtype=torch.float)\n","    return users, items, ratings\n","\n","# Bayesian SVD++ 모델 정의\n","class BayesianSVDppModel:\n","    def __init__(self, num_users, num_items, embedding_size):\n","        self.user_mean = torch.nn.Parameter(torch.zeros(num_users))\n","        self.item_mean = torch.nn.Parameter(torch.zeros(num_items))\n","        self.user_embedding = torch.nn.Embedding(num_users, embedding_size)\n","        self.item_embedding = torch.nn.Embedding(num_items, embedding_size)\n","        self.alpha_u = torch.nn.Embedding(num_users, embedding_size)\n","        self.alpha_i = torch.nn.Embedding(num_items, embedding_size)\n","\n","    def model(self, users, items, ratings):\n","        user_mean = self.user_mean[users]\n","        item_mean = self.item_mean[items]\n","        user_embedding = self.user_embedding(users)\n","        item_embedding = self.item_embedding(items)\n","        alpha_u = self.alpha_u(users)\n","        alpha_i = self.alpha_i(items)\n","\n","        prediction = user_mean + item_mean + torch.sum(user_embedding * item_embedding, dim=1) + torch.sum(alpha_u * alpha_i, dim=1)\n","        obs = pyro.sample(\"obs\", dist.Normal(prediction, 1.0).to_event(1), obs=ratings)\n","\n","    def guide(self, users, items, ratings):\n","        # Variational parameters\n","        user_mean_loc = pyro.param(\"user_mean_loc\", torch.zeros(num_users))\n","        user_mean_scale = pyro.param(\"user_mean_scale\", torch.ones(num_users), constraint=dist.constraints.positive)\n","        item_mean_loc = pyro.param(\"item_mean_loc\", torch.zeros(num_items))\n","        item_mean_scale = pyro.param(\"item_mean_scale\", torch.ones(num_items), constraint=dist.constraints.positive)\n","        user_embedding_loc = pyro.param(\"user_embedding_loc\", torch.randn(num_users, embedding_size))\n","        user_embedding_scale = pyro.param(\"user_embedding_scale\", torch.ones(num_users, embedding_size), constraint=dist.constraints.positive)\n","        item_embedding_loc = pyro.param(\"item_embedding_loc\", torch.randn(num_items, embedding_size))\n","        item_embedding_scale = pyro.param(\"item_embedding_scale\", torch.ones(num_items, embedding_size), constraint=dist.constraints.positive)\n","        alpha_u_loc = pyro.param(\"alpha_u_loc\", torch.randn(num_users, embedding_size))\n","        alpha_u_scale = pyro.param(\"alpha_u_scale\", torch.ones(num_users, embedding_size), constraint=dist.constraints.positive)\n","        alpha_i_loc = pyro.param(\"alpha_i_loc\", torch.randn(num_items, embedding_size))\n","        alpha_i_scale = pyro.param(\"alpha_i_scale\", torch.ones(num_items, embedding_size), constraint=dist.constraints.positive)\n","\n","        # Sample from variational distribution\n","        pyro.sample(\"user_mean\", dist.Normal(user_mean_loc, user_mean_scale))\n","        pyro.sample(\"item_mean\", dist.Normal(item_mean_loc, item_mean_scale))\n","        pyro.sample(\"user_embedding\", dist.Normal(user_embedding_loc, user_embedding_scale))\n","        pyro.sample(\"item_embedding\", dist.Normal(item_embedding_loc, item_embedding_scale))\n","        pyro.sample(\"alpha_u\", dist.Normal(alpha_u_loc, alpha_u_scale))\n","        pyro.sample(\"alpha_i\", dist.Normal(alpha_i_loc, alpha_i_scale))\n","\n","# 데이터 전처리 및 DataLoader 생성\n","# ...\n","\n","# 모델 초기화\n","num_users = len(user_encoder.classes_)\n","num_items = len(item_encoder.classes_)\n","embedding_size = 32\n","\n","bayesian_svdpp_model = BayesianSVDppModel(num_users, num_items, embedding_size)\n","\n","# 손실 함수 및 최적화 함수 정의\n","optimizer = Adam({\"lr\": 0.01})\n","svi = SVI(bayesian_svdpp_model.model, bayesian_svdpp_model.guide, optimizer, loss=Trace_ELBO())\n","\n","# 학습\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    loss = 0.0\n","    for batch in train_loader:\n","        users, items, ratings = batch\n","        loss += svi.step(users, items, ratings)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss / len(train_loader)}\")\n","\n","# 예측\n","bayesian_svdpp_model.eval()\n","with torch.no_grad():\n","    all_predictions = []\n","    for batch in test_loader:\n","        users, items, ratings = batch\n","        predictions = bayesian_svdpp_model.model(users, items, ratings)\n","        all_predictions.extend(predictions.numpy())\n","\n","test_rmse = mean_squared_error(test_ratings, all_predictions, squared=False)\n","print(f'Test RMSE: {test_rmse}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":762},"id":"H8bgN0loWkCV","executionInfo":{"status":"error","timestamp":1701853320677,"user_tz":-540,"elapsed":4575,"user":{"displayName":"나주영","userId":"11176719384042417975"}},"outputId":"0d626831-b359-4de4-c9ba-2951bd8ab6e0"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.10/dist-packages (1.8.6)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (3.3.0)\n","Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (0.1.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (4.66.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pyro-ppl) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pyro-ppl) (1.3.0)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-b257ad77d8ec>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss / len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         params = set(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             loss_particle, surrogate_loss_particle = self._differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m                 \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         model_trace, guide_trace = get_importance_trace(\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;34m\"flat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_plate_nesting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mcheck_site_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_plate_nesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/util.py\u001b[0m in \u001b[0;36mcheck_site_shape\u001b[0;34m(site, max_plate_nesting)\u001b[0m\n\u001b[1;32m    435\u001b[0m     ):\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpected_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexpected_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mactual_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    438\u001b[0m                 \"\\n  \".join(\n\u001b[1;32m    439\u001b[0m                     [\n","\u001b[0;31mValueError\u001b[0m: at site \"user_mean\", invalid log_prob shape\n  Expected [], actual [24458]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with pyro.plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions"]}]}]}